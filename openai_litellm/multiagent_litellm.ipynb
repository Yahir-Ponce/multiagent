{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo de Agentes con LiteLLM (Azure/OpenAI)\n",
    "\n",
    "**Objetivo.** Tener varios agentes y llamar solo al que se necesite; además, un agente *triage* decide a cuál delegar según el idioma.  \n",
    "**Enfoque.** Comentarios concisos, instrucciones claras y pasos listos para ejecutar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos rápidos\n",
    "\n",
    "- Python 3.10+\n",
    "- Paquetes: `python-dotenv` y las dependencias de tu framework (`agents`, `litellm`, etc.).  \n",
    "- Archivo `.env` con:\n",
    "  - `AZURE_API_KEY` (si usas Azure)\n",
    "  - `AZURE_OPENAI_DEPLOYMENT_NAME` (nombre del *deployment* en Azure)\n",
    "\n",
    "> Si usas OpenAI en lugar de Azure, ajusta el nombre del modelo/deployment según tu configuración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuración del entorno\n",
    "\n",
    "- Carga variables con `dotenv`.\n",
    "- Desactiva *tracing* si no lo necesitas.\n",
    "- Lee `AZURE_API_KEY` y `AZURE_OPENAI_DEPLOYMENT_NAME` desde el entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Tool de ejemplo (function calling)\n",
    "\n",
    "`get_weather(city, unit)` es una *tool* de demostración.  \n",
    "- Propósito: mostrar cómo un agente puede invocar funciones.  \n",
    "- En producción: conecta aquí tu API real (clima, RAG, BD, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ea9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from agents import Agent, Runner, set_tracing_disabled, function_tool, ModelSettings\n",
    "from agents.extensions.models.litellm_model import LitellmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83005e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "API_KEY    = os.getenv(\"AZURE_API_KEY\")\n",
    "DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39d9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_weather(city: str, unit: str = \"C\") -> str:\n",
    "    \"\"\"\n",
    "    Devuelve clima falso (demo).\n",
    "    \"\"\"\n",
    "    fake = {\n",
    "        \"Monterrey\": {\"C\": \"32°C, soleado\", \"F\": \"89.6°F, soleado\"},\n",
    "        \"CDMX\": {\"C\": \"22°C, nublado\", \"F\": \"71.6°F, nublado\"},\n",
    "        \"Madrid\": {\"C\": \"25°C, claro\", \"F\": \"77°F, claro\"},\n",
    "    }\n",
    "    data = fake.get(city, {\"C\": \"N/D\", \"F\": \"N/D\"}).get(unit, \"N/D\")\n",
    "    return f\"Clima en {city}: {data}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Agente en español\n",
    "\n",
    "- Responde en español, breve y directo.  \n",
    "- Puede invocar la tool `get_weather` si el usuario pide clima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db016de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=(\n",
    "        \"Responde en español, breve y directo. \"\n",
    "        \"Si el usuario pide clima, llama a la tool get_weather.\"\n",
    "    ),\n",
    "    model=f\"litellm/azure/{DEPLOYMENT}\",\n",
    "    tools=[get_weather],\n",
    "    model_settings=ModelSettings(include_usage=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Agente en inglés\n",
    "\n",
    "- Responde en inglés, conciso.  \n",
    "- También puede usar `get_weather` si aplica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f803eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_agent = Agent(\n",
    "    name=\"English Assistant\",\n",
    "    instructions=(\n",
    "        \"Reply in concise English. \"\n",
    "        \"If the user requests weather, call get_weather.\"\n",
    "    ),\n",
    "    model=LitellmModel(\n",
    "        model=f\"azure/{DEPLOYMENT}\",\n",
    "        api_key=API_KEY\n",
    "    ),\n",
    "    tools=[get_weather],\n",
    "    model_settings=ModelSettings(include_usage=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Agente *triage* (handoff por idioma)\n",
    "\n",
    "- Detecta el idioma del mensaje.  \n",
    "- **Español →** delega a *Spanish agent*.  \n",
    "- **Inglés →** delega a *English Assistant*.  \n",
    "- No explica la decisión; solo responde o delega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807123bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=(\n",
    "        \"Decide el handoff: si el mensaje está mayormente en español -> Spanish agent; \"\n",
    "        \"si está en inglés -> English Assistant. Si dudas, responde en el idioma detectado. \"\n",
    "        \"No expliques la decisión, solo responde o delega.\"\n",
    "    ),\n",
    "    model=f\"litellm/azure/{DEPLOYMENT}\",\n",
    "    handoffs=[spanish_agent, english_agent],\n",
    "    model_settings=ModelSettings(include_usage=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Pruebas rápidas\n",
    "\n",
    "Ejemplos:\n",
    "- Llamada al *triage* con mensaje en español e inglés.  \n",
    "- Llamada directa a un agente específico.  \n",
    "- Uso de la tool `get_weather` de forma implícita.\n",
    "\n",
    "> Tip: ajusta las *prompts* de prueba a tu caso real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b945bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yahir.ponce\\OneDrive - Softtek\\Documents\\multiagent\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_typing_extra.py:378: RuntimeWarning: coroutine 'AgentRunner.run' was never awaited\n",
      "  return eval_type_backport(value, globalns, localns), True\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRIAGE -> AUTO] (español):\n",
      "El clima en Monterrey es de 32°C y soleado.\n",
      "\n",
      "[TRIAGE -> AUTO] (english):\n",
      "The weather in Madrid is 77°F and clear.\n",
      "\n",
      "[DIRECT -> Spanish agent]:\n",
      "RAG (Retrieval-Augmented Generation) es una técnica que combina la generación de texto con la recuperación de información, permitiendo a los modelos acceder a una base de datos externa para mejorar la calidad y precisión de las respuestas. Este enfoque es útil en tareas como la respuesta a preguntas y la generación de contenido informativo.\n",
      "\n",
      "[DIRECT -> English Assistant + tool]:\n",
      "The weather in CDMX is 22°C and cloudy.\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Handoff automático por idioma ---\n",
    "r1 = await Runner.run(triage_agent, input=\"¿Me dices el clima de Monterrey en C?\")\n",
    "print(\"\\n[TRIAGE -> AUTO] (español):\")\n",
    "print(r1.final_output)\n",
    "\n",
    "r2 = await Runner.run(triage_agent, input=\"What's the weather in Madrid in F?\")\n",
    "print(\"\\n[TRIAGE -> AUTO] (english):\")\n",
    "print(r2.final_output)\n",
    "\n",
    "# --- 2) Llamada directa a un solo agente ---\n",
    "r3 = await Runner.run(spanish_agent, input=\"Dame un resumen en 2 líneas de RAG.\")\n",
    "print(\"\\n[DIRECT -> Spanish agent]:\")\n",
    "print(r3.final_output)\n",
    "\n",
    "# --- 3) Tool explícita (demostración) ---\n",
    "r4 = await Runner.run(english_agent, input=\"Get me the weather for CDMX in C.\")\n",
    "print(\"\\n[DIRECT -> English Assistant + tool]:\")\n",
    "print(r4.final_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
